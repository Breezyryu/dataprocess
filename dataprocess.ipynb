{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ë°°í„°ë¦¬ ë°ì´í„° ì‚¬ì´í´ëŸ¬ ë¶„ë¥˜ ë° ë¡œë”© ì‹œìŠ¤í…œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë°°í„°ë¦¬ ì¶©ë°©ì „ ë°ì´í„° ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ **í† ìš”(Toyo)** ë˜ëŠ” **PNE** ì‚¬ì´í´ëŸ¬ë¡œ ë¶„ë¥˜í•˜ê³ , ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ë¶„ë¥˜ ê¸°ì¤€**:\n",
    "- **PNE**: Pattern í´ë”ê°€ ì¡´ì¬í•˜ëŠ” ê²½ë¡œ\n",
    "- **Toyo**: Pattern í´ë”ê°€ ì—†ëŠ” ê²½ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functions_header",
   "metadata": {},
   "source": [
    "## ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cycler(path: str) -> str:\n",
    "    \"\"\"\n",
    "    ê²½ë¡œì˜ ì‚¬ì´í´ëŸ¬ íƒ€ì…ì„ ì‹ë³„í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        í™•ì¸í•  ë°ì´í„° ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        'PNE' ë˜ëŠ” 'Toyo' ë˜ëŠ” 'Unknown'\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return \"Unknown (ê²½ë¡œ ì—†ìŒ)\"\n",
    "    \n",
    "    # Pattern í´ë” ì¡´ì¬ ì—¬ë¶€ë¡œ PNEì™€ Toyo êµ¬ë¶„\n",
    "    pattern_path = os.path.join(path, \"Pattern\")\n",
    "    \n",
    "    if os.path.isdir(pattern_path):\n",
    "        return \"PNE\"\n",
    "    else:\n",
    "        return \"Toyo\"\n",
    "\n",
    "\n",
    "def extract_capacity_from_path(path: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    ê²½ë¡œëª…ì—ì„œ ìš©ëŸ‰ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        ë¶„ì„í•  ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float or None\n",
    "        ì¶”ì¶œëœ ìš©ëŸ‰(mAh), ì—†ìœ¼ë©´ None\n",
    "    \"\"\"\n",
    "    # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ mAh ì¶”ì¶œ\n",
    "    match = re.search(r'(\\d+([\\-.]\\d+)?)mAh', path)\n",
    "    if match:\n",
    "        capacity_str = match.group(1).replace('-', '.')\n",
    "        return float(capacity_str)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_directory_info(path: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ì˜ ë©”íƒ€ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        ë¶„ì„í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        ë””ë ‰í† ë¦¬ ì •ë³´ (í•˜ìœ„ í´ë” ìˆ˜, íŒŒì¼ ìˆ˜ ë“±)\n",
    "    \"\"\"\n",
    "    info = {\n",
    "        'exists': False,\n",
    "        'subdirs': 0,\n",
    "        'files': 0,\n",
    "        'has_pattern_folder': False,\n",
    "        'file_types': set()\n",
    "    }\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        return info\n",
    "    \n",
    "    info['exists'] = True\n",
    "    \n",
    "    try:\n",
    "        items = os.listdir(path)\n",
    "        \n",
    "        for item in items:\n",
    "            item_path = os.path.join(path, item)\n",
    "            \n",
    "            if os.path.isdir(item_path):\n",
    "                info['subdirs'] += 1\n",
    "                if item.lower() == 'pattern':\n",
    "                    info['has_pattern_folder'] = True\n",
    "            else:\n",
    "                info['files'] += 1\n",
    "                # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ\n",
    "                _, ext = os.path.splitext(item)\n",
    "                if ext:\n",
    "                    info['file_types'].add(ext.lower())\n",
    "    \n",
    "    except PermissionError:\n",
    "        info['error'] = 'ê¶Œí•œ ì—†ìŒ'\n",
    "    except Exception as e:\n",
    "        info['error'] = str(e)\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def classify_battery_paths(path_list: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ë°°í„°ë¦¬ ë°ì´í„° ê²½ë¡œë¥¼ ì¼ê´„ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path_list : List[str]\n",
    "        ë¶„ë¥˜í•  ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        ë¶„ë¥˜ ê²°ê³¼ê°€ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for path in path_list:\n",
    "        # ê¸°ë³¸ ì •ë³´\n",
    "        cycler_type = check_cycler(path)\n",
    "        dir_info = get_directory_info(path)\n",
    "        capacity = extract_capacity_from_path(path)\n",
    "        \n",
    "        # ê²½ë¡œì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ê°€ë…ì„±)\n",
    "        path_name = os.path.basename(path)\n",
    "        \n",
    "        results.append({\n",
    "            'ê²½ë¡œ': path,\n",
    "            'í´ë”ëª…': path_name,\n",
    "            'ì‚¬ì´í´ëŸ¬': cycler_type,\n",
    "            'ìš©ëŸ‰(mAh)': capacity if capacity else '-',\n",
    "            'í•˜ìœ„í´ë”ìˆ˜': dir_info['subdirs'],\n",
    "            'íŒŒì¼ìˆ˜': dir_info['files'],\n",
    "            'Patterní´ë”': 'ìˆìŒ' if dir_info['has_pattern_folder'] else 'ì—†ìŒ',\n",
    "            'ì¡´ì¬ì—¬ë¶€': 'ì¡´ì¬' if dir_info['exists'] else 'ì—†ìŒ'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pne_functions_header",
   "metadata": {},
   "source": [
    "## PNE ë°ì´í„° ë¡œë”© í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pne_data_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_restore_folders(pne_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    PNE ê²½ë¡œì—ì„œ Restore í´ë”ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pne_path : str\n",
    "        PNE ë°ì´í„° ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    List[str]\n",
    "        Restore í´ë” ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    restore_folders = []\n",
    "    \n",
    "    # M##Ch###[###] í˜•ì‹ì˜ ì±„ë„ í´ë” ì°¾ê¸°\n",
    "    for item in os.listdir(pne_path):\n",
    "        item_path = os.path.join(pne_path, item)\n",
    "        if os.path.isdir(item_path) and re.match(r'M\\d+Ch\\d+\\[\\d+\\]', item):\n",
    "            # Restore í´ë” í™•ì¸\n",
    "            restore_path = os.path.join(item_path, 'Restore')\n",
    "            if os.path.isdir(restore_path):\n",
    "                restore_folders.append(restore_path)\n",
    "    \n",
    "    return sorted(restore_folders)\n",
    "\n",
    "\n",
    "def load_pne_profile_data(restore_path: str, max_files: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PNE Restore í´ë”ì—ì„œ ì‹œê³„ì—´ í”„ë¡œíŒŒì¼ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\n",
    "    SaveData íŒŒì¼ë“¤(SaveEndData ì œì™¸)ì„ ìˆœì„œëŒ€ë¡œ ì½ì–´ì„œ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    restore_path : str\n",
    "        Restore í´ë” ê²½ë¡œ\n",
    "    max_files : int, optional\n",
    "        ì½ì„ ìµœëŒ€ íŒŒì¼ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        í•©ì³ì§„ ì‹œê³„ì—´ í”„ë¡œíŒŒì¼ ë°ì´í„°\n",
    "    \"\"\"\n",
    "    # SaveData íŒŒì¼ë“¤ ì°¾ê¸° (ch##_SaveData####.csv í˜•ì‹, SaveEndData ì œì™¸)\n",
    "    savedata_pattern = os.path.join(restore_path, '*_SaveData*.csv')\n",
    "    all_files = glob.glob(savedata_pattern)\n",
    "    \n",
    "    # SaveEndData.csv ì œì™¸ (í”„ë¡œíŒŒì¼ ë°ì´í„°ë§Œ)\n",
    "    savedata_files = [f for f in all_files if 'SaveEndData' not in f]\n",
    "    \n",
    "    if not savedata_files:\n",
    "        print(f\"ê²½ê³ : {restore_path}ì—ì„œ í”„ë¡œíŒŒì¼ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œí•˜ì—¬ ì •ë ¬ (ch09_SaveData0001.csv -> 1)\n",
    "    def extract_file_number(filepath):\n",
    "        match = re.search(r'SaveData(\\d+)\\.csv', filepath)\n",
    "        return int(match.group(1)) if match else 0\n",
    "    \n",
    "    savedata_files = sorted(savedata_files, key=extract_file_number)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ìš©: íŒŒì¼ ê°œìˆ˜ ì œí•œ\n",
    "    if max_files:\n",
    "        savedata_files = savedata_files[:max_files]\n",
    "    \n",
    "    print(f\"ğŸ“Š í”„ë¡œíŒŒì¼ ë°ì´í„°: {len(savedata_files)}ê°œì˜ SaveData íŒŒì¼ ë°œê²¬\")\n",
    "    print(f\"   ì²« íŒŒì¼: {os.path.basename(savedata_files[0])}\")\n",
    "    print(f\"   ë§ˆì§€ë§‰ íŒŒì¼: {os.path.basename(savedata_files[-1])}\")\n",
    "    \n",
    "    # ì‹œê³„ì—´ ìˆœì„œëŒ€ë¡œ íŒŒì¼ ì½ì–´ì„œ í•©ì¹˜ê¸°\n",
    "    dfs = []\n",
    "    for i, file_path in enumerate(savedata_files):\n",
    "        try:\n",
    "            # CSV íŒŒì¼ ì½ê¸° (í—¤ë” ì—†ìŒ, ì½¤ë§ˆ êµ¬ë¶„)\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            dfs.append(df)\n",
    "            \n",
    "            # ì§„í–‰ ìƒí™© ì¶œë ¥ (10ê°œë§ˆë‹¤)\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"   ì§„í–‰: {i + 1}/{len(savedata_files)} íŒŒì¼ ë¡œë”© ì™„ë£Œ\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ê²½ê³ : {os.path.basename(file_path)} ë¡œë”© ì‹¤íŒ¨ - {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not dfs:\n",
    "        print(\"   ì˜¤ë¥˜: ë¡œë”©ëœ í”„ë¡œíŒŒì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # ëª¨ë“  DataFrameì„ ì‹œê³„ì—´ ìˆœì„œë¡œ í•©ì¹˜ê¸°\n",
    "    combined_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    print(f\"   âœ… í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(combined_df):,}í–‰ x {len(combined_df.columns)}ì—´\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def load_pne_cycle_data(restore_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PNE Restore í´ë”ì—ì„œ ì‚¬ì´í´ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\n",
    "    SaveEndData.csv íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    restore_path : str\n",
    "        Restore í´ë” ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        ì‚¬ì´í´ ë°ì´í„°\n",
    "    \"\"\"\n",
    "    # SaveEndData.csv íŒŒì¼ ì°¾ê¸°\n",
    "    saveend_pattern = os.path.join(restore_path, '*_SaveEndData.csv')\n",
    "    saveend_files = glob.glob(saveend_pattern)\n",
    "    \n",
    "    if not saveend_files:\n",
    "        print(f\"ê²½ê³ : {restore_path}ì—ì„œ SaveEndData íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ SaveEndData íŒŒì¼ ì‚¬ìš©\n",
    "    saveend_file = saveend_files[0]\n",
    "    \n",
    "    print(f\"ğŸ”„ ì‚¬ì´í´ ë°ì´í„°: {os.path.basename(saveend_file)}\")\n",
    "    \n",
    "    try:\n",
    "        # CSV íŒŒì¼ ì½ê¸° (í—¤ë” ì—†ìŒ, ì½¤ë§ˆ êµ¬ë¶„)\n",
    "        df = pd.read_csv(saveend_file, header=None)\n",
    "        print(f\"   âœ… ì‚¬ì´í´ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df):,}í–‰ x {len(df.columns)}ì—´\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ì˜¤ë¥˜: SaveEndData ë¡œë”© ì‹¤íŒ¨ - {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_pne_channel_data(pne_path: str, channel_index: int = 0, max_files: Optional[int] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    PNE ê²½ë¡œì—ì„œ íŠ¹ì • ì±„ë„ì˜ í”„ë¡œíŒŒì¼ ë° ì‚¬ì´í´ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pne_path : str\n",
    "        PNE ë°ì´í„° ê²½ë¡œ\n",
    "    channel_index : int\n",
    "        ì±„ë„ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)\n",
    "    max_files : int, optional\n",
    "        ì½ì„ ìµœëŒ€ í”„ë¡œíŒŒì¼ íŒŒì¼ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        {\n",
    "            'channel_name': str,\n",
    "            'restore_path': str,\n",
    "            'profile_data': DataFrame (ì‹œê³„ì—´ í”„ë¡œíŒŒì¼),\n",
    "            'cycle_data': DataFrame (ì‚¬ì´í´ ë°ì´í„°)\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Restore í´ë” ì°¾ê¸°\n",
    "    restore_folders = find_restore_folders(pne_path)\n",
    "    \n",
    "    if not restore_folders:\n",
    "        print(f\"ê²½ê³ : {pne_path}ì—ì„œ Restore í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return {\n",
    "            'channel_name': None,\n",
    "            'restore_path': None,\n",
    "            'profile_data': pd.DataFrame(),\n",
    "            'cycle_data': pd.DataFrame()\n",
    "        }\n",
    "    \n",
    "    print(f\"\\në°œê²¬ëœ Restore í´ë”: {len(restore_folders)}ê°œ\")\n",
    "    for i, folder in enumerate(restore_folders):\n",
    "        print(f\"  [{i}] {os.path.dirname(folder).split(os.sep)[-1]}\")\n",
    "    \n",
    "    if channel_index >= len(restore_folders):\n",
    "        print(f\"ì˜¤ë¥˜: ì±„ë„ ì¸ë±ìŠ¤ {channel_index}ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.\")\n",
    "        return {\n",
    "            'channel_name': None,\n",
    "            'restore_path': None,\n",
    "            'profile_data': pd.DataFrame(),\n",
    "            'cycle_data': pd.DataFrame()\n",
    "        }\n",
    "    \n",
    "    # ì„ íƒëœ ì±„ë„ì˜ ë°ì´í„° ë¡œë”©\n",
    "    selected_restore = restore_folders[channel_index]\n",
    "    channel_name = os.path.dirname(selected_restore).split(os.sep)[-1]\n",
    "    \n",
    "    print(f\"\\nì„ íƒëœ ì±„ë„: {channel_name}\")\n",
    "    print(f\"Restore ê²½ë¡œ: {selected_restore}\")\n",
    "    print(\"\\në°ì´í„° ë¡œë”© ì¤‘...\\n\")\n",
    "    \n",
    "    # í”„ë¡œíŒŒì¼ ë°ì´í„°ì™€ ì‚¬ì´í´ ë°ì´í„° ê°ê° ë¡œë”©\n",
    "    profile_data = load_pne_profile_data(selected_restore, max_files=max_files)\n",
    "    cycle_data = load_pne_cycle_data(selected_restore)\n",
    "    \n",
    "    return {\n",
    "        'channel_name': channel_name,\n",
    "        'restore_path': selected_restore,\n",
    "        'profile_data': profile_data,\n",
    "        'cycle_data': cycle_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "path_input_header",
   "metadata": {},
   "source": [
    "## ê²½ë¡œ ì…ë ¥\n",
    "\n",
    "ë¶„ì„í•  ë°°í„°ë¦¬ ë°ì´í„° ê²½ë¡œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "path_input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ê¸°ì¡´ ê²½ë¡œë“¤)\n",
    "paths = [\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\250207_250307_3_ê¹€ë™ì§„_1689mAh_ATL Q7M Inner 2C ìƒì˜¨ìˆ˜ëª… 1-100cyc\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\250219_250319_3_ê¹€ë™ì§„_1689mAh_ATL Q7M Inner 2C ìƒì˜¨ìˆ˜ëª… 101-200cyc\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\250304_250404_3_ê¹€ë™ì§„_1689mAh_ATL Q7M Inner 2C ìƒì˜¨ìˆ˜ëª… 201-300cyc\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\250317_251231_3_ê¹€ë™ì§„_1689mAh_ATL Q7M Inner 2C ìƒì˜¨ìˆ˜ëª… 301-400cyc\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\A1_MP1_4500mAh_T23_1\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\A1_MP1_4500mAh_T23_2\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\A1_MP1_4500mAh_T23_3\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\Dateset_A1_Gen4 2C ATL MP2 [45V 4470mAh] [23] blk2\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\Gen4 2C ATL MP2 [45V 4470mAh] [23] blk7 - 240131\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\M1 ATL [45V 4175mAh]\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\Q7M Inner ATL_45V 1689mAh BLK1 20EA [23] - 250304\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\Q7M Main ATL [45V_1680mAh][23] blk7 20ea - 250228\",\n",
    "    r\"C:\\Users\\Ryu\\Python_project\\data\\ì›ë³¸ - ë³µì‚¬ë³¸\\Rawdata\\Q7M Sub ATL [45v 2068mAh] [23] - 250219r\"\n",
    "]\n",
    "\n",
    "print(f\"ì´ {len(paths)}ê°œ ê²½ë¡œê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classification_header",
   "metadata": {},
   "source": [
    "## ì‚¬ì´í´ëŸ¬ ìë™ ë¶„ë¥˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ë¶„ë¥˜ ì‹¤í–‰\n",
    "results_df = classify_battery_paths(paths)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n=== ë°°í„°ë¦¬ ë°ì´í„° ì‚¬ì´í´ëŸ¬ ë¶„ë¥˜ ê²°ê³¼ ===\")\n",
    "print(f\"\\nì´ ë¶„ì„ ê²½ë¡œ: {len(results_df)}ê°œ\")\n",
    "print(f\"\\nì‚¬ì´í´ëŸ¬ íƒ€ì…ë³„ í†µê³„:\")\n",
    "print(results_df['ì‚¬ì´í´ëŸ¬'].value_counts())\n",
    "\n",
    "# ì „ì²´ ê²°ê³¼ í…Œì´ë¸” (ê²½ë¡œ ì œì™¸ - ê°€ë…ì„±)\n",
    "display_df = results_df.drop(columns=['ê²½ë¡œ'])\n",
    "display(display_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pne_data_loading_header",
   "metadata": {},
   "source": [
    "## PNE ë°ì´í„° ë¡œë”© ì˜ˆì œ\n",
    "\n",
    "PNE ê²½ë¡œì—ì„œ Restore í´ë”ì˜ **í”„ë¡œíŒŒì¼ ë°ì´í„°**(SaveData)ì™€ **ì‚¬ì´í´ ë°ì´í„°**(SaveEndData)ë¥¼ ê°ê° ë¡œë”©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pne_example_selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNE ê²½ë¡œ í•„í„°ë§\n",
    "pne_paths = results_df[results_df['ì‚¬ì´í´ëŸ¬'] == 'PNE']['ê²½ë¡œ'].tolist()\n",
    "\n",
    "if pne_paths:\n",
    "    print(f\"ë°œê²¬ëœ PNE ê²½ë¡œ: {len(pne_paths)}ê°œ\\n\")\n",
    "    for i, path in enumerate(pne_paths):\n",
    "        print(f\"[{i}] {os.path.basename(path)}\")\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ PNE ê²½ë¡œ ì„ íƒ\n",
    "    selected_pne_path = pne_paths[0]\n",
    "    print(f\"\\nì„ íƒëœ ê²½ë¡œ: {os.path.basename(selected_pne_path)}\")\n",
    "else:\n",
    "    print(\"PNE ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    selected_pne_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pne_data_loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNE ë°ì´í„° ë¡œë”© (í…ŒìŠ¤íŠ¸: ì²˜ìŒ 5ê°œ í”„ë¡œíŒŒì¼ íŒŒì¼ë§Œ)\n",
    "if selected_pne_path:\n",
    "    channel_data = get_pne_channel_data(\n",
    "        selected_pne_path, \n",
    "        channel_index=0,  # ì²« ë²ˆì§¸ ì±„ë„\n",
    "        max_files=5       # í…ŒìŠ¤íŠ¸ìš©: 5ê°œ íŒŒì¼ë§Œ (Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë¡œë”©)\n",
    "    )\n",
    "    \n",
    "    # ë¡œë”©ëœ ë°ì´í„° í™•ì¸\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"=== ë¡œë”© ì™„ë£Œ ===\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ì±„ë„ëª…: {channel_data['channel_name']}\")\n",
    "    print(f\"\\ní”„ë¡œíŒŒì¼ ë°ì´í„° shape: {channel_data['profile_data'].shape}\")\n",
    "    print(f\"ì‚¬ì´í´ ë°ì´í„° shape: {channel_data['cycle_data'].shape}\")\n",
    "    \n",
    "    # í”„ë¡œíŒŒì¼ ë°ì´í„° í™•ì¸\n",
    "    if not channel_data['profile_data'].empty:\n",
    "        print(f\"\\n=== í”„ë¡œíŒŒì¼ ë°ì´í„° (ì‹œê³„ì—´) ===\")\n",
    "        print(f\"ì²˜ìŒ 10í–‰:\")\
