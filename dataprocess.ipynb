{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ë°°í„°ë¦¬ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ\n",
        "\n",
        "ë°°í„°ë¦¬ ì¶©ë°©ì „ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ë¶„ì„í•˜ëŠ” ë²”ìš© ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
        "\n",
        "## ê¸°ëŠ¥\n",
        "- ìë™ ì‚¬ì´í´ëŸ¬ ë¶„ë¥˜ (Toyo/PNE)\n",
        "- ë©”íƒ€ ì •ë³´ ì¶”ì¶œ\n",
        "- ì›ì‹œ ë°ì´í„° ë¡œë”©\n",
        "- ì‹œê°í™”\n",
        "- ê²°ê³¼ ì €ì¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup: í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_cycler(raw_file_path):\n",
        "    \"\"\"\n",
        "    ì¶©ë°©ì „ê¸° êµ¬ë¶„ (íŒ¨í„´ í´ë” ìœ ë¬´ë¡œ êµ¬ë¶„)\n",
        "    \n",
        "    Parameters:\n",
        "        raw_file_path (str): ë¶„ì„í•  ë°ì´í„° ê²½ë¡œ\n",
        "    \n",
        "    Returns:\n",
        "        str: 'PNE' ë˜ëŠ” 'Toyo'\n",
        "    \"\"\"\n",
        "    # ì¶©ë°©ì „ê¸° ë°ì´í„° í´ë”ì— íŒ¨í„´ í´ë” ìœ ë¬´ë¡œ PNEì™€ Toyo êµ¬ë¶„\n",
        "    has_pattern = os.path.isdir(os.path.join(raw_file_path, \"Pattern\"))\n",
        "    return \"PNE\" if has_pattern else \"Toyo\"\n",
        "\n",
        "\n",
        "def name_capacity(data_file_path):\n",
        "    \"\"\"\n",
        "    filepath ì´ë¦„ì—ì„œ ìš©ëŸ‰ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
        "    \n",
        "    Parameters:\n",
        "        data_file_path (str): ë°ì´í„° ê²½ë¡œ\n",
        "    \n",
        "    Returns:\n",
        "        float or None: ì¶”ì¶œëœ ìš©ëŸ‰ (mAh), ì—†ìœ¼ë©´ None\n",
        "    \"\"\"\n",
        "    # ì›ì‹œ ë¬¸ìì—´ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ìˆ˜ ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´\n",
        "    raw_file_path = re.sub(r'[._@\\$\\(\\)]', ' ', data_file_path)\n",
        "    # ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ \"mAh\"ë¡œ ëë‚˜ëŠ” ìš©ëŸ‰ ê°’ì„ ì°¾ìŠµë‹ˆë‹¤. (ì†Œìˆ˜ì  í¬í•¨)\n",
        "    match = re.search(r'(\\d+([\\-.]\\d+)?)mAh', raw_file_path)\n",
        "    if match:\n",
        "        # ì†Œìˆ˜ì  ìš©ëŸ‰ì„ ìœ„í•´ -ë¥¼ .ìœ¼ë¡œ ë³€í™˜\n",
        "        min_cap = match.group(1).replace('-', '.')\n",
        "        return float(min_cap)\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_directory_info(path):\n",
        "    \"\"\"\n",
        "    ë””ë ‰í† ë¦¬ ë©”íƒ€ ì •ë³´ ì¶”ì¶œ\n",
        "    \n",
        "    Parameters:\n",
        "        path (str): ë¶„ì„í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
        "    \n",
        "    Returns:\n",
        "        dict: í´ë”ëª…, ì„œë¸Œí´ë” ê°œìˆ˜, íŒŒì¼ ê°œìˆ˜, Pattern í´ë” ìœ ë¬´, ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€\n",
        "    \"\"\"\n",
        "    info = {\n",
        "        'path': path,\n",
        "        'folder_name': os.path.basename(path),\n",
        "        'exists': os.path.exists(path),\n",
        "        'has_pattern': False,\n",
        "        'num_subfolders': 0,\n",
        "        'num_files': 0,\n",
        "        'cycler_type': 'Unknown',\n",
        "        'capacity_mAh': None\n",
        "    }\n",
        "    \n",
        "    if info['exists']:\n",
        "        # Pattern í´ë” í™•ì¸\n",
        "        info['has_pattern'] = os.path.isdir(os.path.join(path, \"Pattern\"))\n",
        "        \n",
        "        # ì‚¬ì´í´ëŸ¬ íƒ€ì… ê²°ì •\n",
        "        info['cycler_type'] = check_cycler(path)\n",
        "        \n",
        "        # ì„œë¸Œí´ë” ë° íŒŒì¼ ê°œìˆ˜\n",
        "        try:\n",
        "            items = os.listdir(path)\n",
        "            for item in items:\n",
        "                item_path = os.path.join(path, item)\n",
        "                if os.path.isdir(item_path):\n",
        "                    info['num_subfolders'] += 1\n",
        "                else:\n",
        "                    info['num_files'] += 1\n",
        "        except PermissionError:\n",
        "            pass\n",
        "        \n",
        "        # ìš©ëŸ‰ ì¶”ì¶œ\n",
        "        info['capacity_mAh'] = name_capacity(path)\n",
        "    \n",
        "    return info\n",
        "\n",
        "\n",
        "print(\"âœ… ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ê²½ë¡œ ì…ë ¥\n",
        "\n",
        "**ì—¬ê¸°ì— ë¶„ì„í•  ë°°í„°ë¦¬ ë°ì´í„° ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¶„ì„í•  ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì‚¬ìš©ìê°€ ìˆ˜ì •)\n",
        "paths = [\n",
        "    r\"C:\\Users\\Ryu\\Python_project\\data\\dataprocess\\Rawdata\\A1_MP1_4500mAh_T23_1\",\n",
        "    # ì¶”ê°€ ê²½ë¡œë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”\n",
        "    # r\"D:\\Battery_Data\\Path2\",\n",
        "    # r\"D:\\Battery_Data\\Path3\",\n",
        "]\n",
        "\n",
        "print(f\"ë¶„ì„ ëŒ€ìƒ ê²½ë¡œ ê°œìˆ˜: {len(paths)}\")\n",
        "for i, path in enumerate(paths, 1):\n",
        "    print(f\"  {i}. {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ìë™ ë¶„ë¥˜: ë°ì´í„° ìŠ¤ìº” ë° ì‚¬ì´í´ëŸ¬ íƒ€ì… ì‹ë³„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ìˆ˜ì§‘\n",
        "results = []\n",
        "\n",
        "for path in paths:\n",
        "    print(f\"ë¶„ì„ ì¤‘: {path}\")\n",
        "    info = get_directory_info(path)\n",
        "    results.append(info)\n",
        "\n",
        "# DataFrame ìƒì„±\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "print(f\"\\nâœ… ì´ {len(df_results)}ê°œ ê²½ë¡œ ë¶„ì„ ì™„ë£Œ\")\n",
        "\n",
        "# ì‚¬ì´í´ëŸ¬ íƒ€ì…ë³„ í†µê³„\n",
        "print(\"\\n=== ì‚¬ì´í´ëŸ¬ íƒ€ì…ë³„ í†µê³„ ===\")\n",
        "print(df_results['cycler_type'].value_counts())\n",
        "\n",
        "# ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”\n",
        "print(\"\\n=== ìƒì„¸ ë¶„ë¥˜ ê²°ê³¼ ===\")\n",
        "display_cols = ['folder_name', 'cycler_type', 'capacity_mAh', 'num_subfolders', 'num_files', 'has_pattern', 'exists']\n",
        "print(df_results[display_cols].to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "### PNE ë° Toyo ì‚¬ì´í´ëŸ¬ì˜ ì›ì‹œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== PNE ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ==========\n",
        "\n",
        "def load_pne_cycle_data(path):\n",
        "    \"\"\"\n",
        "    PNE ì‚¬ì´í´ ë°ì´í„° ë¡œë”© (SaveEndData.csv)\n",
        "    \n",
        "    Parameters:\n",
        "        path (str): PNE ë°ì´í„° ê²½ë¡œ\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame or None: ì‚¬ì´í´ ë°ì´í„° DataFrame\n",
        "    \"\"\"\n",
        "    restore_path = os.path.join(path, \"Restore\")\n",
        "    \n",
        "    if not os.path.isdir(restore_path):\n",
        "        print(f\"âš ï¸  Restore í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {path}\")\n",
        "        return None\n",
        "    \n",
        "    # SaveEndData.csv íŒŒì¼ ì°¾ê¸°\n",
        "    csv_files = [f for f in os.listdir(restore_path) if f.endswith('.csv')]\n",
        "    end_data_file = None\n",
        "    \n",
        "    for file in csv_files:\n",
        "        if 'SaveEndData' in file:\n",
        "            end_data_file = file\n",
        "            break\n",
        "    \n",
        "    if not end_data_file:\n",
        "        print(f\"âš ï¸  SaveEndData.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {restore_path}\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        file_path = os.path.join(restore_path, end_data_file)\n",
        "        if os.stat(file_path).st_size == 0:\n",
        "            print(f\"âš ï¸  ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {end_data_file}\")\n",
        "            return None\n",
        "        \n",
        "        # CSV ë¡œë“œ (ì»¬ëŸ¼ í—¤ë” ì—†ìŒ)\n",
        "        df = pd.read_csv(file_path, sep=',', skiprows=0, engine='c', \n",
        "                        header=None, encoding='cp949', on_bad_lines='skip')\n",
        "        \n",
        "        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ: 27(ì‚¬ì´í´), 2(ì¡°ê±´), 11(ë°©ì „ìš©ëŸ‰), 9(ì „ë¥˜), 24(ì˜¨ë„), 6(ì¢…ë£Œìƒíƒœ), 8(ì „ì••)\n",
        "        df = df[[27, 2, 11, 9, 24, 6, 8]]\n",
        "        df.columns = ['Cycle', 'Condition', 'DchgCap_mAh', 'Current_mA', 'Temp_C', 'EndState', 'Voltage_mV']\n",
        "        \n",
        "        # ì˜¨ë„ ë° ì „ì•• ë‹¨ìœ„ ë³€í™˜\n",
        "        df['Temp_C'] = df['Temp_C'] / 1000\n",
        "        df['Voltage_mV'] = df['Voltage_mV'] / 1000\n",
        "        df['Current_mA'] = df['Current_mA'] / 1000\n",
        "        \n",
        "        print(f\"âœ… PNE ì‚¬ì´í´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} rows\")\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ PNE ì‚¬ì´í´ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_pne_profile_data(path, max_files=10):\n",
        "    \"\"\"\n",
        "    PNE í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë”© (SaveData*.csv)\n",
        "    \n",
        "    Parameters:\n",
        "        path (str): PNE ë°ì´í„° ê²½ë¡œ\n",
        "        max_files (int): ë¡œë“œí•  ìµœëŒ€ íŒŒì¼ ê°œìˆ˜\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame or None: í”„ë¡œíŒŒì¼ ë°ì´í„° DataFrame\n",
        "    \"\"\"\n",
        "    restore_path = os.path.join(path, \"Restore\")\n",
        "    \n",
        "    if not os.path.isdir(restore_path):\n",
        "        return None\n",
        "    \n",
        "    # SaveDataë¡œ ì‹œì‘í•˜ëŠ” CSV íŒŒì¼ ì°¾ê¸°\n",
        "    csv_files = [f for f in os.listdir(restore_path) \n",
        "                 if f.endswith('.csv') and 'SaveData' in f and 'SaveEndData' not in f]\n",
        "    csv_files.sort()  # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬\n",
        "    \n",
        "    if not csv_files:\n",
        "        print(f\"âš ï¸  SaveData íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {restore_path}\")\n",
        "        return None\n",
        "    \n",
        "    # ìµœëŒ€ íŒŒì¼ ê°œìˆ˜ ì œí•œ\n",
        "    csv_files = csv_files[:max_files]\n",
        "    \n",
        "    dataframes = []\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            file_path = os.path.join(restore_path, file)\n",
        "            df_temp = pd.read_csv(file_path, sep=',', skiprows=0, engine='c',\n",
        "                                 header=None, encoding='cp949', on_bad_lines='skip')\n",
        "            dataframes.append(df_temp)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  íŒŒì¼ ë¡œë”© ì‹¤íŒ¨ ({file}): {e}\")\n",
        "            continue\n",
        "    \n",
        "    if dataframes:\n",
        "        df_combined = pd.concat(dataframes, ignore_index=True)\n",
        "        print(f\"âœ… PNE í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(csv_files)}ê°œ íŒŒì¼, {len(df_combined)} rows\")\n",
        "        return df_combined\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ========== Toyo ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ==========\n",
        "\n",
        "def find_toyo_channel_folders(path):\n",
        "    \"\"\"\n",
        "    Toyo ì±„ë„ í´ë” ì°¾ê¸° (ìˆ«ìë¡œë§Œ ì´ë£¨ì–´ì§„ í´ë”)\n",
        "    \n",
        "    Parameters:\n",
        "        path (str): Toyo ë°ì´í„° ê²½ë¡œ\n",
        "    \n",
        "    Returns:\n",
        "        list: ì±„ë„ í´ë” ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        return []\n",
        "    \n",
        "    channel_folders = []\n",
        "    for item in os.listdir(path):\n",
        "        item_path = os.path.join(path, item)\n",
        "        if os.path.isdir(item_path) and item.isdigit():\n",
        "            channel_folders.append(item_path)\n",
        "    \n",
        "    channel_folders.sort()\n",
        "    return channel_folders\n",
        "\n",
        "\n",
        "def load_toyo_cycle_data(channel_path):\n",
        "    \"\"\"\n",
        "    Toyo ì‚¬ì´í´ ë°ì´í„° ë¡œë”© (capacity.log)\n",
        "    \n",
        "    Parameters:\n",
        "        channel_path (str): Toyo ì±„ë„ í´ë” ê²½ë¡œ\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame or None: ì‚¬ì´í´ ë°ì´í„° DataFrame\n",
        "    \"\"\"\n",
        "    capacity_file = os.path.join(channel_path, 'capacity.log')\n",
        "    \n",
        "    if not os.path.isfile(capacity_file):\n",
        "        print(f\"âš ï¸  capacity.log íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {channel_path}\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(capacity_file, sep=',', skiprows=0, engine='c', \n",
        "                        encoding='cp949', on_bad_lines='skip')\n",
        "        \n",
        "        # ì»¬ëŸ¼ëª… í‘œì¤€í™” (Toyo ì¶©ë°©ì „ê¸° íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)\n",
        "        if 'Cap[mAh]' in df.columns:\n",
        "            # BLK 3600/3000 íƒ€ì…\n",
        "            df = df[['TotlCycle', 'Condition', 'Cap[mAh]', 'Ocv', 'PeakTemp[Deg]', 'AveVolt[V]']]\n",
        "            df.columns = ['Cycle', 'Condition', 'Capacity_mAh', 'OCV_V', 'Temp_C', 'AvgVolt_V']\n",
        "        elif 'Capacity[mAh]' in df.columns:\n",
        "            # BLK 5200 íƒ€ì…\n",
        "            df = df[['Total Cycle', 'Condition', 'Capacity[mAh]', 'OCV[V]', 'Peak Temp.[deg]', 'Ave. Volt.[V]']]\n",
        "            df.columns = ['Cycle', 'Condition', 'Capacity_mAh', 'OCV_V', 'Temp_C', 'AvgVolt_V']\n",
        "        \n",
        "        print(f\"âœ… Toyo ì‚¬ì´í´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} rows\")\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Toyo ì‚¬ì´í´ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_toyo_profile_data(channel_path, max_cycles=5):\n",
        "    \"\"\"\n",
        "    Toyo í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë”© (%06d í˜•ì‹ íŒŒì¼)\n",
        "    \n",
        "    Parameters:\n",
        "        channel_path (str): Toyo ì±„ë„ í´ë” ê²½ë¡œ\n",
        "        max_cycles (int): ë¡œë“œí•  ìµœëŒ€ ì‚¬ì´í´ ê°œìˆ˜\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame or None: í”„ë¡œíŒŒì¼ ë°ì´í„° DataFrame\n",
        "    \"\"\"\n",
        "    dataframes = []\n",
        "    \n",
        "    for cycle in range(1, max_cycles + 1):\n",
        "        profile_file = os.path.join(channel_path, f\"{cycle:06d}\")\n",
        "        \n",
        "        if not os.path.isfile(profile_file):\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            df_temp = pd.read_csv(profile_file, sep=',', skiprows=3, engine='c',\n",
        "                                 encoding='cp949', on_bad_lines='skip')\n",
        "            \n",
        "            # ì»¬ëŸ¼ëª… í‘œì¤€í™”\n",
        "            if 'PassTime[Sec]' in df_temp.columns:\n",
        "                df_temp = df_temp[['PassTime[Sec]', 'Voltage[V]', 'Current[mA]', 'Condition']]\n",
        "                df_temp.columns = ['Time_s', 'Voltage_V', 'Current_mA', 'Condition']\n",
        "            elif 'Passed Time[Sec]' in df_temp.columns:\n",
        "                df_temp = df_temp[['Passed Time[Sec]', 'Voltage[V]', 'Current[mA]', 'Condition']]\n",
        "                df_temp.columns = ['Time_s', 'Voltage_V', 'Current_mA', 'Condition']\n",
        "            \n",
        "            df_temp['Cycle'] = cycle\n",
        "            dataframes.append(df_temp)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  ì‚¬ì´í´ {cycle} íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if dataframes:\n",
        "        df_combined = pd.concat(dataframes, ignore_index=True)\n",
        "        print(f\"âœ… Toyo í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(dataframes)}ê°œ ì‚¬ì´í´, {len(df_combined)} rows\")\n",
        "        return df_combined\n",
        "    else:\n",
        "        print(f\"âš ï¸  í”„ë¡œíŒŒì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {channel_path}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"âœ… ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ì›ì‹œ ë°ì´í„° ë¡œë”© ì‹¤í–‰\n",
        "\n",
        "ê° ê²½ë¡œì˜ ì‚¬ì´í´ëŸ¬ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ë°ì´í„° ë¡œë”©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¡œë“œëœ ë°ì´í„°ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
        "loaded_data = {\n",
        "    'pne_cycle': {},\n",
        "    'pne_profile': {},\n",
        "    'toyo_cycle': {},\n",
        "    'toyo_profile': {}\n",
        "}\n",
        "\n",
        "# ê° ê²½ë¡œë³„ë¡œ ë°ì´í„° ë¡œë”©\n",
        "for idx, row in df_results.iterrows():\n",
        "    path = row['path']\n",
        "    folder_name = row['folder_name']\n",
        "    cycler_type = row['cycler_type']\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ“ ê²½ë¡œ: {folder_name}\")\n",
        "    print(f\"ğŸ”§ íƒ€ì…: {cycler_type}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    if cycler_type == 'PNE':\n",
        "        # PNE ì‚¬ì´í´ ë°ì´í„° ë¡œë”©\n",
        "        cycle_df = load_pne_cycle_data(path)\n",
        "        if cycle_df is not None:\n",
        "            loaded_data['pne_cycle'][folder_name] = cycle_df\n",
        "        \n",
        "        # PNE í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë”© (ì²˜ìŒ 5ê°œ íŒŒì¼ë§Œ)\n",
        "        profile_df = load_pne_profile_data(path, max_files=5)\n",
        "        if profile_df is not None:\n",
        "            loaded_data['pne_profile'][folder_name] = profile_df\n",
        "    \n",
        "    elif cycler_type == 'Toyo':\n",
        "        # Toyo ì±„ë„ í´ë” ì°¾ê¸°\n",
        "        channel_folders = find_toyo_channel_folders(path)\n",
        "        \n",
        "        if channel_folders:\n",
        "            print(f\"  ğŸ“‚ ë°œê²¬ëœ ì±„ë„ í´ë”: {len(channel_folders)}ê°œ\")\n",
        "            \n",
        "            # ì²« ë²ˆì§¸ ì±„ë„ë§Œ ë¡œë“œ (ì˜ˆì‹œ)\n",
        "            first_channel = channel_folders[0]\n",
        "            channel_name = os.path.basename(first_channel)\n",
        "            \n",
        "            print(f\"  ğŸ”„ ì±„ë„ {channel_name} ë¡œë”© ì¤‘...\")\n",
        "            \n",
        "            # Toyo ì‚¬ì´í´ ë°ì´í„° ë¡œë”©\n",
        "            cycle_df = load_toyo_cycle_data(first_channel)\n",
        "            if cycle_df is not None:\n",
        "                loaded_data['toyo_cycle'][f\"{folder_name}_ch{channel_name}\"] = cycle_df\n",
        "            \n",
        "            # Toyo í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë”© (ì²˜ìŒ 3ê°œ ì‚¬ì´í´ë§Œ)\n",
        "            profile_df = load_toyo_profile_data(first_channel, max_cycles=3)\n",
        "            if profile_df is not None:\n",
        "                loaded_data['toyo_profile'][f\"{folder_name}_ch{channel_name}\"] = profile_df\n",
        "        else:\n",
        "            print(f\"  âš ï¸  ì±„ë„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "\n",
        "print(f\"\\n\\n{'='*60}\")\n",
        "print(\"ğŸ“Š ë°ì´í„° ë¡œë”© ìš”ì•½\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  PNE ì‚¬ì´í´ ë°ì´í„°: {len(loaded_data['pne_cycle'])}ê°œ\")\n",
        "print(f\"  PNE í”„ë¡œíŒŒì¼ ë°ì´í„°: {len(loaded_data['pne_profile'])}ê°œ\")\n",
        "print(f\"  Toyo ì‚¬ì´í´ ë°ì´í„°: {len(loaded_data['toyo_cycle'])}ê°œ\")\n",
        "print(f\"  Toyo í”„ë¡œíŒŒì¼ ë°ì´í„°: {len(loaded_data['toyo_profile'])}ê°œ\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ë¡œë“œëœ ë°ì´í„° í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PNE ì‚¬ì´í´ ë°ì´í„° ìƒ˜í”Œ\n",
        "if loaded_data['pne_cycle']:\n",
        "    first_key = list(loaded_data['pne_cycle'].keys())[0]\n",
        "    print(f\"ğŸ“Œ PNE ì‚¬ì´í´ ë°ì´í„° ìƒ˜í”Œ ({first_key}):\")\n",
        "    display(loaded_data['pne_cycle'][first_key].head(10))\n",
        "else:\n",
        "    print(\"PNE ì‚¬ì´í´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Toyo ì‚¬ì´í´ ë°ì´í„° ìƒ˜í”Œ\n",
        "if loaded_data['toyo_cycle']:\n",
        "    first_key = list(loaded_data['toyo_cycle'].keys())[0]\n",
        "    print(f\"ğŸ“Œ Toyo ì‚¬ì´í´ ë°ì´í„° ìƒ˜í”Œ ({first_key}):\")\n",
        "    display(loaded_data['toyo_cycle'][first_key].head(10))\n",
        "else:\n",
        "    print(\"Toyo ì‚¬ì´í´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ê²°ê³¼ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì „ì²´ ê²°ê³¼ DataFrame ì¶œë ¥\n",
        "df_results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
